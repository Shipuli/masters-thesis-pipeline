Flume cassandra no good integrations
=> plugins unmaintained
=> rip

DBs need processing jobs in order to digest from kafka

Docker images are not that used? Newer thing that can help development when this logic is decoupled from the OS

Big data europe has made docker containers for hadoop ecosystem

Uses traefik which is not needed

Kafka does not have easy ways to create topic
=> most production ready way is to use AdminAPI and create a new application

Kafka has no web ui to check what is up
=> https://stackoverflow.com/questions/49276785/monitoring-ui-for-apache-kafka-kafka-manager-vs-kafka-monitor/49292872
=> TL;DR not many "good" non-commercial solutions


Errors while developing
- Cache problems => Errors that made no sense (file corruption)
- Not enough memory => Silently killing processess (scala)
- Kafka connect => Worker is killed but process continues (aka Kafka HDFS integration)
  - Namenode did not have enough time to setup => inf while loop to ping namenode
  - Connection error: Protocol message end-group tag did not match expected tag. => wrong port (right port 9000)
  - Wrong serializer => JSON when actually String needed
  - Cannot read files from HDFS (concerns only web ui, see TODO)
  - org.apache.avro.AvroRuntimeException: already open => flush size set to 1 with one partition https://github.com/confluentinc/kafka-connect-hdfs/issues/298
- Spark HDFS integration
  - Avro package in sbt dependencies was not enough => had to use --packages flag
  - https://issues.apache.org/jira/browse/SPARK-27623 => downgrade package
  - https://datameer.zendesk.com/hc/en-us/articles/213151023-java-nio-channels-SocketChannel-connection-pending-remote-IP-port- => add config to spark context
  - java.nio.channels.UnresolvedAddressException (no other information given) => More information with spark Debug flags => HDFS uses docker random generated hashes for hostnames => No solution => stab /etc/hosts
  - Exception in thread "main" org.apache.spark.sql.avro.IncompatibleSchemaException: Found recursive reference in Avro schema, which can not be processed by Spark: => Avro schema is automatically generated by kafka-connect and this does not work with Spark => change save file format to json (side effect: code no longer errors from docker hashes)
- Zeppelin
  - java.lang.IncompatibleClassChangeError: Implementing class => Zeppelin fails to start the spark interpreter based on modified interpreter.json. Did not find any good solutions. One way to go around this is to run the code once to get the error. Then go to settings and save the settings which causes some the interpreter to restart and this seems to fix this. (note: doing restart via restart button does not fix this)
  - Could not fetch dependencies for interpreter 'spark.spark', reason: undefined => interpreter.json had one comma too much

Other notes:
- Spark still does not support latest scala version (current: 2.13, supported: 2.12)
- Zeppelin docker container has a habit of getting stuck if used too much (docker restart needed)
- DL4J is really nitpicky when it comes to the format of the input. In cloud environment CSV is only format that is actually well supported.

TODO problems:
- HDFS permissions (?) do not allow web ui file downloads


Bits of info that probably should be kept safe:
Kafka data isn't indexed by key, it's partitioned by it,